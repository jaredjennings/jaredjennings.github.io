<!DOCTYPE html>
<html lang="en">
<head>
          <title>Writing to think 2: Write harder - igrating from TheHive 3 to 4</title>
        <meta charset="utf-8" />





</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">Writing to think 2: Write harder <strong></strong></a></h1>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
            <li><a href="/category/commentary.html">Commentary</a></li>
            <li><a href="/category/compliance-at-home.html">Compliance at home</a></li>
            <li><a href="/category/editors.html">Editors</a></li>
            <li><a href="/category/emacs.html">Emacs</a></li>
            <li class="active"><a href="/category/misc.html">misc</a></li>
            <li><a href="/category/projects.html">Projects</a></li>
            <li><a href="/category/security.html">Security</a></li>
            <li><a href="/category/uncategorized.html">Uncategorized</a></li>
            <li><a href="/category/untangling.html">Untangling</a></li>
        </ul></nav><!-- /#menu -->
<section id="content" class="body">
  <header>
    <h2 class="entry-title">
      <a href="/igrating-from-thehive-3-to-4.html" rel="bookmark"
         title="Permalink to igrating from TheHive 3 to 4">igrating from TheHive 3 to 4</a></h2>
 
  </header>
  <footer class="post-info">
    <time class="published" datetime="2021-07-09T15:08:00-04:00">
      Fri 09 July 2021
    </time>
    <address class="vcard author">
      By           <a class="url fn" href="/author/jaredj.html">jaredj</a>
    </address>
    <div class="category">
        Category: <a href="/category/misc.html">misc</a>
    </div>
  </footer><!-- /.post-info -->
  <div class="entry-content">
    <div class="section" id="preconditions">
<h2>Preconditions</h2>
<blockquote>
<ol class="arabic simple">
<li>It is mid-2021. TheHive 4.1 is current.</li>
<li>TheHive 3.4.0, Cortex 3.0.0, and Elasticsearch 5.6.0 are installed
on a single Linux server using packages. Let us call it <cite>jimmy</cite>.</li>
<li>Elasticsearch only accepts connections from <tt class="docutils literal">localhost</tt>, and
they are unauthenticated and unencrypted.</li>
<li>Snapshots can be taken to a local directory.</li>
<li>A Kubernetes cluster is set up. It provides persistent volumes
using a <tt class="docutils literal">storageClass</tt> of <tt class="docutils literal">longhorn</tt>.</li>
<li>Elastic Cloud on Kubernetes (ECK) is already installed.</li>
<li>Web proxy settings need not be specifically provided, but Web
traffic goes through a filtering proxy that inspects TLS traffic
by performing a MitM attack. Consequently, an additional
organization-specific root CA must be trusted in order to get any
HTTPS done.</li>
</ol>
</blockquote>
</div>
<div class="section" id="postconditions">
<h2>Postconditions</h2>
<blockquote>
<ol class="arabic simple">
<li>A ScyllaDB database has been set up.</li>
<li>A Hive 4.1 instance is set up.</li>
<li>Data (cases, observables, tasks) is stored in the ScyllaDB
database and visible by TheHive 4.1.</li>
</ol>
</blockquote>
</div>
<div class="section" id="lemmas">
<h2>Lemmas</h2>
<p>In the course of this, a few things which may be interesting in their
own right are done:</p>
<blockquote>
<ul class="simple">
<li>Elasticsearch is deployed using ECK, pulling in the S3 snapshot
plugin from behind a TLS-rewriting proxy.</li>
</ul>
</blockquote>
</div>
<div class="section" id="lorem-ipsum">
<h2>Lorem ipsum</h2>
<p>Example names and words chosen throughout this document are listed
here. If your configuration contains any of these strings, you may
need to replace them with values more specific to the context in which
you are working.</p>
<blockquote>
<ul class="simple">
<li><tt class="docutils literal">jimmy</tt></li>
<li><tt class="docutils literal">emili</tt></li>
<li><tt class="docutils literal">k.example.org</tt></li>
<li><tt class="docutils literal">example.org</tt></li>
<li><tt class="docutils literal">pY8Il9uhRxIh</tt></li>
<li><tt class="docutils literal">ateljevic</tt></li>
<li><tt class="docutils literal">jitendraa3</tt></li>
<li><tt class="docutils literal">changeit</tt>. This is often used for Java trust stores, because the
store password is not securing any private keys, but it's good
to make something random.</li>
<li><tt class="docutils literal">ljungstrand</tt></li>
<li><tt class="docutils literal">pataki</tt></li>
<li><tt class="docutils literal">karstensen</tt></li>
</ul>
</blockquote>
</div>
<div class="section" id="relevant-documentation">
<h2>Relevant documentation</h2>
<blockquote>
<ul class="simple">
<li><a class="reference external" href="http://docs.thehive-project.org/thehive/operations/migration/">Migration from TheHive 3.x</a></li>
<li><a class="reference external" href="http://docs.thehive-project.org/thehive/legacy/thehive3/migration-guide/">3.4.x -&gt; 3.5.0 migration guide</a></li>
</ul>
</blockquote>
<p>There are two paths outlined:</p>
<blockquote>
<ul class="simple">
<li>3.4.x -&gt; 3.5.x -&gt; 4.1.x; or</li>
<li>3.4.x -&gt; 4.0.x -&gt; 4.1.x.</li>
</ul>
</blockquote>
</div>
<div class="section" id="procedure">
<h2>Procedure</h2>
<div class="section" id="reindex-es5-data-in-es6">
<h3>Reindex ES5 data in ES6</h3>
<blockquote>
<ol class="arabic">
<li><p class="first">Take a snapshot, which we shall call <cite>es5original</cite>. On <cite>jimmy</cite>:</p>
<pre class="literal-block">
curl -XPUT http://localhost:9200/_snapshot/local/es5original\?wait_for_completion=true
</pre>
</li>
<li><p class="first">Run a temporary <a class="reference external" href="https://docs.min.io/docs/minio-quickstart-guide">MinIO server</a> on some
host. Let us refer to this host as <cite>emili</cite>.</p>
<pre class="literal-block">
MINIO_ROOT_USER=ateljevic MINIO_ROOT_PASSWORD=jitendraa3 \
  ./minio server --address localhost:9300 /tmp/a_bucket
</pre>
</li>
<li><p class="first">Run a <a class="reference external" href="https://docs.min.io/docs/minio-client-quickstart-guide">mc command-line client</a>. Prompts for access key and secret key will show; these
should be the values given for MINIO_ROOT_USER and
MINIO_ROOT_PASSWORD from above.</p>
</li>
<li><p class="first">Place the Elastic snapshot data taken in step 1 inside the
directory MinIO is serving.</p>
</li>
<li><p class="first">On your Kubernetes cluster, set up a Secret for Elasticsearch to
get the credentials from. (Use the same values given above for
MINIO_ROOT_USER and MINIO_ROOT_PASSWORD.</p>
<pre class="literal-block">
kubectl create secret generic ephemeral-minio \
  --from-literal=s3.client.local_minio_snapshots.access_key=ateljevic \
  '--from-literal=s3.client.local_minio_snapshots.secret_key=jitendraa3'
</pre>
</li>
<li><p class="first">Create a Secret with the root CA that must be trusted in order to
do HTTPS through the organization's filtering proxy.</p>
<pre class="literal-block">
mkdir root-ca
cat &gt; root-ca/ca.crt &lt;&lt;ITSOVER
----- BEGIN CERTIFICATE ------
pY8Il9uhRxIhRm5WehfcxZeLmXea7O6EszrYarwO+rmm/07jUS43wLZB+Js6xxQLJLeLDKMMuLFq
jEma8ttQE1ZWhZjHYxwBziWagpFUp1jXauak4/OJrd6ijrmolTC1fmt9ff3T6R7w1qYqhs74/3ad
[...]
----- END CERTIFICATE -----
ITSOVER
kubectl create secret generic root-ca --from-file=root-ca
</pre>
</li>
<li><p class="first">Write this description of the ElasticSearch 6 cluster into <tt class="docutils literal">es6.yaml</tt>.</p>
<pre class="literal-block">
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  namespace: hivemig
  name: es6
spec:
  version: 6.8.12
  secureSettings:
    - secretName: ephemeral-minio
  nodeSets:
    - name: default
      count: 1
      config:
        node.master: true
        node.data: true
        node.ingest: true
        action.auto_create_index: .watches,.triggered_watches,.watcher-history-*
        s3.client.default.protocol: http
        s3.client.default.endpoint: &quot;emili.example.org:9300&quot;
      podTemplate:
        spec:
          volumes:
            - name: trust
              emptyDir: {}
            - name: root-ca
              secret:
                secretName: root-ca
          initContainers:
          - name: sysctl
            securityContext:
              privileged: true
            command: ['sh', '-c', 'sysctl -w vm.max_map_count=262144']
          # trust our root CA so we can fetch the s3 plugin from the web
          - name: trust-our-root
            volumeMounts:
              - name: trust
                mountPath: /trust
              - name: root-ca
                mountPath: /root-ca
            command: ['sh', '-c', '$(find /opt -name keytool | head -n 1) -import -keystore /trust/store -storetype jks -alias root-ca -file /root-ca/ca.crt -storepass changeit -trustcacerts -noprompt']
          - name: install-plugins
            volumeMounts:
              - name: trust
                mountPath: /trust
            env:
              - name: ES_JAVA_OPTS
                value: &quot;-Djavax.net.ssl.trustStore=/trust/store -Djavax.net.debug=all&quot;
            command: ['sh', '-c', 'bin/elasticsearch-plugin install --batch repository-s3']
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 10Gi
          storageClassName: longhorn
</pre>
</li>
<li><p class="first">Create the ES6 cluster including the S3 plugin using ECK. <a class="reference external" href="https://www.kubernet.dev/set-a-default-namespace-for-kubectl/">Change
your default namespace</a>.</p>
<pre class="literal-block">
kubectl create ns hivemig
kubectl config set-context --current --namespace=hivemig
kubectl apply -f es6.yaml
</pre>
</li>
<li><p class="first">Tell the ES6 server about the snapshot repository. Note that the
es6.yaml configures the default S3 client settings to point at
<tt class="docutils literal">emili</tt>, and that default client is used for this repository.</p>
<pre class="literal-block">
EPASS=$(kubectl get -o jsonpath='{.data.elastic}' secret es6-es-elastic-user | base64 -d)
SVCIP=$(kubectl get svc es6-es-http -o jsonpath='{.spec.clusterIPs[0]}')
curl -k -u elastic:$EPASS -XPUT -H 'content-type: application/json' \
  https://$SVCIP:9200/_snapshot/my_minio \
  -d '{&quot;type&quot;:&quot;s3&quot;, &quot;settings&quot;:{ &quot;bucket&quot;: &quot;elastic_snapshots&quot;}}'
</pre>
</li>
<li><p class="first">Tell the ES6 server to restore the snapshot.</p>
<pre class="literal-block">
curl -k -u elastic:$EPASS https://$SVCIP:9200/_snapshot/my_minio/es5original
curl -k -u elastic:$EPASS -XPOST https://$SVCIP:9200/_snapshot/my_minio/es5original/_restore
</pre>
</li>
<li><p class="first">Do the <a class="reference external" href="http://docs.thehive-project.org/thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#create-a-new-index">reindexing</a>
in the 3.5.0 migration guide.</p>
<pre class="literal-block">
curl -k -u elastic:$EPASS -XPUT &quot;https://${SVCIP}:9200/new_the_hive_15&quot; \
      -H 'content-type: application/json' \
      -d &quot;$(curl -k -u elastic:$EPASS https://${SVCIP}:9200/the_hive_15 | jq '.the_hive_15 | del(.settings.index.provided_name, .settings.index.uuid, .settings.index.version, .settings.index.mapping.single_type, .settings.index.creation_date, .mappings.doc._all)')&quot;
 curl -k -u elastic:$EPASS -XPOST \
      -H 'Content-type: application/json' https://$SVCIP:9200/_reindex \
      -d '{&quot;conflicts&quot;:&quot;proceed&quot;,&quot;source&quot;:{&quot;index&quot;:&quot;the_hive_15&quot;}, &quot;dest&quot;:{&quot;index&quot;:&quot;new_the_hive_15&quot;}}'
 curl -k -u elastic:$EPASS -XPUT &quot;https://${SVCIP}:9200/new_cortex_4&quot; \
      -H 'content-type: application/json' \
      -d &quot;$(curl -k -u elastic:$EPASS https://${SVCIP}:9200/cortex_4 | jq '.cortex_4 | del(.settings.index.provided_name, .settings.index.uuid, .settings.index.version, .settings.index.mapping.single_type, .settings.index.creation_date, .mappings.doc._all)')&quot;
 curl -k -u elastic:$EPASS -XPOST \
      -H 'Content-type: application/json' https://$SVCIP:9200/_reindex \
      -d '{&quot;conflicts&quot;:&quot;proceed&quot;,&quot;source&quot;:{&quot;index&quot;:&quot;cortex_4&quot;}, &quot;dest&quot;:{&quot;index&quot;:&quot;new_cortex_4&quot;}}'
 curl -k -u elastic:$EPASS -XPOST -H 'Content-Type: application/json' \
      &quot;https://${SVCIP}:9200/_aliases&quot; -d \
      '{&quot;actions&quot;:[{&quot;add&quot;:{&quot;index&quot;:&quot;new_the_hive_15&quot;,&quot;alias&quot;:&quot;the_hive_15&quot;}},{&quot;add&quot;:{&quot;index&quot;:&quot;new_cortex_4&quot;,&quot;alias&quot;:&quot;cortex_4&quot;}}]}'
</pre>
</li>
<li><p class="first">Snap this as <cite>es6reindex</cite> into the MinIO S3 bucket.</p>
<pre class="literal-block">
curl -k -u elastic:$EPASS -XPUT \
  &quot;https://${SVCIP}:9200/_snapshot/my_minio/es6reindex?wait_for_completion=true&quot;
</pre>
</li>
</ol>
</blockquote>
</div>
<div class="section" id="update-database-with-thehive-3-5-1">
<h3>Update database with TheHive 3.5.1</h3>
<blockquote>
<ol class="arabic" start="13">
<li><p class="first">Run ES7. Write the following into <tt class="docutils literal">es7.yaml</tt>, then run
<tt class="docutils literal">kubectl apply <span class="pre">-f</span> es7.yaml</tt>.</p>
<pre class="literal-block">
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  namespace: hivemig
  name: es7
spec:
  version: 7.10.2
  secureSettings:
    - secretName: ephemeral-minio
  nodeSets:
    - name: default
      count: 3
      config:
        node.master: true
        node.data: true
        node.ingest: true
        action.auto_create_index: .watches,.triggered_watches,.watcher-history-*
        s3.client.default.protocol: http
        s3.client.default.endpoint: &quot;emili.example.org:9300&quot;
      podTemplate:
        spec:
          volumes:
            - name: trust
              emptyDir: {}
            - name: root-ca
              secret:
                secretName: root-ca
          initContainers:
          - name: sysctl
            securityContext:
              privileged: true
            command: ['sh', '-c', 'sysctl -w vm.max_map_count=262144']
          # trust our root CA so we can fetch the s3 plugin from the web
          - name: trust-our-root
            volumeMounts:
              - name: trust
                mountPath: /trust
              - name: root-ca
                mountPath: /root-ca
            command: ['sh', '-c', '$(find / -name keytool | head -n 1) -import -keystore /trust/store -storetype jks -alias root-ca -file /root-ca/ca.crt -storepass changeit -trustcacerts -noprompt']
          - name: install-plugins
            volumeMounts:
              - name: trust
                mountPath: /trust
            env:
              - name: ES_JAVA_OPTS
                value: &quot;-Djavax.net.ssl.trustStore=/trust/store -Djavax.net.debug=all&quot;
            command: ['sh', '-c', 'bin/elasticsearch-plugin install --batch repository-s3']
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 10Gi
          storageClassName: longhorn
</pre>
</li>
<li><p class="first">Tell ES7 about the snapshot repo.</p>
<pre class="literal-block">
EPASS=$(kubectl get -o jsonpath='{.data.elastic}' secret es7-es-elastic-user | base64 -d)
SVCIP=$(kubectl get svc es7-es-http -o jsonpath='{.spec.clusterIPs[0]}')
curl -k -u elastic:$EPASS -XPUT -H 'content-type: application/json' \
     https://$SVCIP:9200/_snapshot/my_minio \
     -d '{&quot;type&quot;:&quot;s3&quot;, &quot;settings&quot;:{ &quot;bucket&quot;: &quot;elastic_snapshots&quot;}}'
</pre>
</li>
<li><p class="first">Restore the snapshot.</p>
<pre class="literal-block">
curl -k -u elastic:$EPASS https://$SVCIP:9200/_snapshot/my_minio/es6reindex
curl -k -u elastic:$EPASS -XPOST https://$SVCIP:9200/_snapshot/my_minio/es6reindex/_restore
curl -k -u elastic:$EPASS https://$SVCIP:9200/_cat/indices\?v
</pre>
</li>
<li><p class="first">Install TheHive 3 using my Helm chart. Write the following YAML
into <tt class="docutils literal">values3.yaml</tt>:</p>
<pre class="literal-block">
image:
  repository: thehiveproject/thehive
  tag: &quot;3.5.1-1&quot;

ingress:
  enabled: true
  hosts:
    - host: hive.k.example.org
      paths:
        - path: /

elasticsearch:
  eck:
    enabled: true
    name: es7
</pre>
<p>Then:</p>
<pre class="literal-block">
helm install -n hivemig h3b helm-thehive -f values3.yaml
</pre>
<p>If you don't already have a copy of the chart cloned:</p>
<pre class="literal-block">
git clone https://github.com/jaredjennings/helm-thehive
</pre>
</li>
<li><p class="first">Visit <a class="reference external" href="http://hive.k.example.org">http://hive.k.example.org</a>. It will tell you it needs to
update the database. Click the button. After it finishes you do
not need to log in.</p>
</li>
<li><p class="first">Now, take a snapshot, which we shall call <cite>th35upgrade</cite>.</p>
<pre class="literal-block">
curl -k -u elastic:$EPASS -XPUT \
  &quot;https://${SVCIP}:9200/_snapshot/my_minio/th35upgrade?wait_for_completion=true&quot;
</pre>
</li>
<li><p class="first">Snag the configuration from the running copy of TheHive 3.</p>
<pre class="literal-block">
H3B_POD=$(kubectl get -o json pod | jq -r '.items[].metadata.name | select(startswith(&quot;th4&quot;))')
kubectl exec $H3B_POD -it -- bash
find /etc/thehive | xargs cat
# copy output to clipboard
</pre>
<p>This will come in handy later when configuring the migration tool.</p>
</li>
<li><p class="first">Uninstall TheHive3.</p>
<pre class="literal-block">
helm uninstall -n hivemig h3b
</pre>
</li>
</ol>
</blockquote>
</div>
<div class="section" id="prepare-configuration-files-and-databases-for-migrate-script">
<h3>Prepare configuration files and databases for migrate script</h3>
<blockquote>
<ol class="arabic" start="21">
<li><p class="first">Make a directory called <tt class="docutils literal"><span class="pre">migration-configs</span></tt>. Put the Hive3
configuration you grabbed into a file called <tt class="docutils literal">hive3.conf</tt>
therein.</p>
<pre class="literal-block">
play.http.secret.key = &quot;ljungstrand pataki&quot;

search {
  index = the_hive
  uri = &quot;https://es7-es-http:9200/&quot;
  keepalive = 1m
  pagesize = 50
  nbshards = 5
  nbreplicas = 1
  connectionRequestTimeout = 120000
  connectTimeout = 120000
  socketTimeout = 120000
  settings {
    mapping.nested_fields.limit = 100
  }
  user = &quot;elastic&quot;
  password = &quot;karstensen&quot;
  keyStore {
    path = &quot;/configs/store-es7&quot;
    type = &quot;JKS&quot;
    # There are no private keys to protect in this trust
    # store, so its password need not actually secure it.
    password = &quot;changeit&quot;
  }
  trustStore {
    path = &quot;/configs/store-es7&quot;
    type = &quot;JKS&quot;
    # There are no private keys to protect in this trust
    # store, so its password need not actually secure it.
    password = &quot;changeit&quot;
  }
}
</pre>
<p>The password for the elastic user in the es7 cluster is in the
<tt class="docutils literal"><span class="pre">es7-elastic-user</span></tt> Kubernetes secret. To get it out:</p>
<pre class="literal-block">
kubectl get secret es7-es-elastic-user -o template='{{.data.elastic | base64decode}}'
</pre>
</li>
<li><p class="first">Construct a Cassandra database into which to migrate the data, as
well as an Elasticsearch 7 instance.</p>
<p>First follow directions in <a class="reference external" href="https://operator.docs.scylladb.com/stable/generic.html">Deploying Scylla on a Kubernetes
Cluster</a>. Then
write <tt class="docutils literal"><span class="pre">scylla-cluster.yaml</span></tt> as follows:</p>
<pre class="literal-block">
# ServiceAccount for scylla members.
apiVersion: v1
kind: ServiceAccount
metadata:
  name: simple-cluster-member
  namespace: hivemig

---

# RoleBinding for scylla members.
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: simple-cluster-member
  namespace: hivemig
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: scyllacluster-member
subjects:
  - kind: ServiceAccount
    name: simple-cluster-member
    namespace: hivemig

---

# Simple Scylla Cluster
apiVersion: scylla.scylladb.com/v1
kind: ScyllaCluster
metadata:
  labels:
    controller-tools.k8s.io: &quot;1.0&quot;
  name: simple-cluster
  namespace: hivemig
spec:
  version: 4.2.0
  agentVersion: 2.2.0
  developerMode: true
  datacenter:
    name: dc1
    racks:
      - name: dc1ra
        scyllaConfig: &quot;scylla-config&quot;
        scyllaAgentConfig: &quot;scylla-agent-config&quot;
        members: 3
        storage:
          capacity: 5Gi
          storageClassName: longhorn
        resources:
          requests:
            cpu: 1
            memory: 1Gi
          limits:
            cpu: 1
            memory: 1Gi
        volumes:
          - name: coredumpfs
            hostPath:
              path: /tmp/coredumps
        volumeMounts:
          - mountPath: /tmp/coredumps
            name: coredumpfs
</pre>
<p>Now <tt class="docutils literal">kubectl apply <span class="pre">-f</span> <span class="pre">scylla-cluster.yaml</span></tt>.</p>
</li>
<li><p class="first">Bring up an Elasticsearch 7 cluster for TheHive4, imaginatively
enough called <tt class="docutils literal">es74h4</tt>. This is the same as es7 but has a
different name; also it will have its own certs and passwords. It
doesn't need the S3 connection to do its job in this context;
that's just there because I copied this entire file from
above. Here's <tt class="docutils literal">es74h4.yaml</tt>:</p>
<pre class="literal-block">
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  namespace: hivemig
  name: es74h4
spec:
  version: 7.10.2
  secureSettings:
    - secretName: ephemeral-minio
  nodeSets:
    - name: default
      count: 3
      config:
        node.master: true
        node.data: true
        node.ingest: true
        action.auto_create_index: .watches,.triggered_watches,.watcher-history-*
        s3.client.default.protocol: http
        s3.client.default.endpoint: &quot;emili.example.org:9300&quot;
      podTemplate:
        spec:
          volumes:
            - name: trust
              emptyDir: {}
            - name: root-ca
              secret:
                secretName: root-ca
          initContainers:
          - name: sysctl
            securityContext:
              privileged: true
            command: ['sh', '-c', 'sysctl -w vm.max_map_count=262144']
          # trust our root CA so we can fetch the s3 plugin from the web
          - name: trust-our-root
            volumeMounts:
              - name: trust
                mountPath: /trust
              - name: root-ca
                mountPath: /root-ca
            command: ['sh', '-c', '$(find / -name keytool | head -n 1) -import -keystore /trust/store -storetype jks -alias root -file /root-ca/ca.crt -storepass changeit -trustcacerts -noprompt']
          - name: install-plugins
            volumeMounts:
              - name: trust
                mountPath: /trust
            env:
              - name: ES_JAVA_OPTS
                value: &quot;-Djavax.net.ssl.trustStore=/trust/store -Djavax.net.debug=all&quot;
            command: ['sh', '-c', 'bin/elasticsearch-plugin install --batch repository-s3']
            # command: ['sh', '-c', 'true']
      volumeClaimTemplates:
      - metadata:
          name: elasticsearch-data
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 10Gi
          storageClassName: longhorn
</pre>
</li>
<li><p class="first">Drum up Hive4 configuration (&quot;Once TheHive4 configuration file
(/etc/thehive/application.conf) is correctly filled you can run
migration tool.&quot;). So write <tt class="docutils literal">values4.yaml</tt> as follows:</p>
<pre class="literal-block">
ingress:
  enabled: true
  hosts:
    - host: hive.k.example.com
      paths:
        - path: /

elasticsearch:
  eck:
    enabled: true
    name: es74h4

storageClass: longhorn

cassandra:
  enabled: false

externalCassandra:
  enabled: true
  hostName: simple-cluster-client
  dbUser:
    name: cassandra
    password: authentication-not-used-right-now
</pre>
<p>Then:</p>
<pre class="literal-block">
helm template -n hivemig th4 helm-thehive -f helm-thehive/values4.yaml
</pre>
<p>Grab the configuration from <tt class="docutils literal">kubectl get configmap
<span class="pre">th4-thehive-etc-th-tmpl</span></tt>, or actually <tt class="docutils literal">helm install <span class="pre">-n</span> hivemig
th4 <span class="pre">helm-thehive</span> <span class="pre">-f</span> values4.yaml</tt>, then do the same <tt class="docutils literal">kubectl
exec ... <span class="pre">-it</span> bash</tt> seen above for grabbing Hive 3 configuration.</p>
<p>As with previous Elasticsearch clusters, the password for the
<tt class="docutils literal">elastic</tt> user for this cluster is in its own
<tt class="docutils literal"><span class="pre">es74h4-es-elastic-user</span></tt> secret.</p>
</li>
<li><p class="first">Get the CA certificates from both elasticsearch clusters and make
truststores containing each.</p>
<pre class="literal-block">
kubectl get secret es7-es-http-certs-public -o json | \
    jq -r '.data[&quot;ca.crt&quot;] | &#64;base64d' &gt; es7-ca.crt
keytool -importcert -file es7-ca.crt -alias es7-ca \
    -keystore store-es7 -storetype JKS -storepass changeit

kubectl get secret es74h4-es-http-certs-public -o json | \
    jq -r '.data[&quot;ca.crt&quot;] | &#64;base64d' &gt; es74h4-ca.crt
keytool -importcert -file es74h4-ca.crt -alias es74h4-ca \
    -keystore store-es74h4 -storetype JKS -storepass changeit
</pre>
<p>Place the files <tt class="docutils literal"><span class="pre">store-es7</span></tt> and <tt class="docutils literal"><span class="pre">store-es74h4</span></tt> into the
<tt class="docutils literal"><span class="pre">migration-configs</span></tt> directory.</p>
</li>
<li><p class="first">Make a secret with all the migration configs and trust stores in
it:</p>
<pre class="literal-block">
kubectl create secret generic migration-configs \
    --from-file=migration-configs
</pre>
</li>
<li><p class="first">Make a secret to store the Play overrides configuration, for
which the code of the migration tool specifically reaches
out. <a class="reference external" href="https://github.com/TheHive-Project/TheHive/blob/7d6d55d6844df96e59769b2ca46dae5627977664/thehive/conf/play/reference-overrides.conf">This file</a>
is not included in TheHive Docker image.</p>
<pre class="literal-block">
mkdir play-overrides
cat &gt; play-overrides/reference-overrides.conf &lt;&lt;BAZINGA
# HTTP filters
 play.filters {
   # name of cookie in which the CSRF token is transmitted to client
   csrf.cookie.name = THEHIVE-XSRF-TOKEN
   # name of header in which the client should send CSRD token
   csrf.header.name = X-THEHIVE-XSRF-TOKEN

   enabled = [
   ]
 }

 play.http.parser.maxDiskBuffer = 128MB
 play.http.parser.maxMemoryBuffer = 256kB


 # Register module for dependency injection
 play.modules.enabled += org.thp.thehive.TheHiveModule

 play.http.session.cookieName = THEHIVE-SESSION

 play.server.provider = org.thp.thehive.CustomAkkaHttpServerProvider

 play.server.http.idleTimeout = 10 minutes

 akka.actor {
   serializers {
     stream = &quot;org.thp.thehive.services.StreamSerializer&quot;
     notification = &quot;org.thp.thehive.services.notification.NotificationSerializer&quot;
     //thehive-schema-updater = &quot;org.thp.thehive.models.SchemaUpdaterSerializer&quot;
     flow = &quot;org.thp.thehive.services.FlowSerializer&quot;
     integrity = &quot;org.thp.thehive.services.IntegrityCheckSerializer&quot;
     caseNumber = &quot;org.thp.thehive.services.CaseNumberSerializer&quot;
   }

   serialization-bindings {
     &quot;org.thp.thehive.services.StreamMessage&quot; = stream
     &quot;org.thp.thehive.services.notification.NotificationMessage&quot; = notification
     //&quot;org.thp.thehive.models.SchemaUpdaterMessage&quot; = thehive-schema-updater
     &quot;org.thp.thehive.services.FlowMessage&quot; = flow
     &quot;org.thp.thehive.services.IntegrityCheckMessage&quot; = integrity
     &quot;org.thp.thehive.services.CaseNumberActor$Message&quot; = caseNumber
   }
 }
 BAZINGA
 kubectl create secret generic play-overrides \
     --from-file=play-overrides
</pre>
</li>
</ol>
</blockquote>
</div>
<div class="section" id="actually-run-the-migration-script">
<h3>Actually run the migration script</h3>
<blockquote>
<ol class="arabic" start="28">
<li><p class="first">Write this into <tt class="docutils literal"><span class="pre">migrate-job.yaml</span></tt>:</p>
<pre class="literal-block">
apiVersion: batch/v1
kind: Job
metadata:
  namespace: hivemig
  name: migration-3to4
spec:
  completions: 1
  backoffLimit: 1
  template:
    spec:
      restartPolicy: Never
      volumes:
        - name: configs
          secret:
            secretName: migration-configs
        - name: play-overrides
          secret:
            secretName: play-overrides
      containers:
        - name: migrate
          image: thehiveproject/thehive4:4.1.7-1
          volumeMounts:
            - name: configs
              mountPath: /configs
            - name: play-overrides
              mountPath: /opt/thehive/config/play
          args:
            - &quot;migrate&quot;
            - &quot;--&quot;
            - &quot;--input&quot;
            - &quot;/configs/hive3.conf&quot;
            - &quot;--output&quot;
            - &quot;/configs/hive4.conf&quot;
            - &quot;--drop-database&quot;
            - &quot;--main-organisation&quot;
            - &quot;example.org&quot;
</pre>
</li>
<li><p class="first">Now <tt class="docutils literal">kubectl apply <span class="pre">-f</span> <span class="pre">migrate-job.yaml</span></tt>.</p>
</li>
<li><p class="first">Follow its logs.</p>
<pre class="literal-block">
MIG_POD=$(kubectl get -o json pod | jq -r '.items[].metadata.name | select(startswith(&quot;migration-3to4&quot;))')
</pre>
</li>
</ol>
</blockquote>
</div>
</div>
<div class="section" id="what-now">
<h2>What now?</h2>
<p>Now you have a new TheHive4 instance with your stuff in it. Do
new-thehive4-instance things, like changing the password of
<a class="reference external" href="mailto:admin&#64;thehive.local">admin&#64;thehive.local</a> post-haste. Refer back to TheHive4 documentation
because you are now more or less back on the beaten path.</p>
</div>
<div class="section" id="what-s-missing">
<h2>What's missing?</h2>
<p>The ScyllaDB set up here does not compel authentication, nor secure
its connections with TLS.</p>
<p>For both Scylla (or Cassandra, if you use that instead) and
Elasticsearch, there are day-2 considerations such as logging,
monitoring, backup, and restoration to deal with. You may need a
long-lived MinIO instance to snap your Elasticsearch cluster into: I
tried a ReadWriteMany PersistentVolume, and it didn't work right. I
think I got one per Elasticsearch node or something.</p>
</div>

  </div><!-- /.entry-content -->
</section>
        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>,
                which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
</body>
</html>